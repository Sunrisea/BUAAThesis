\chapter{NALTP模型实验与验证}

为了验证本课题提出的NATLP算法的有效性，本文进行了实验验证。本章首先对NALTP的实验方案设计进行了介绍，包括实验采用的数据集、实验环境、评估策略；用来对比的基线算法以及模型在两个数据集上的超参数设置，并对实验结果进行了详细的分析，包括整体性能分析、关键设计分析。

\section{实验方案设计}

\subsection{实验数据集}
为了对NATLP模型进行评估，本文在两个标准基准数据集FB15k-237\upcite{FB15k-237}和WN18RR\upcite{ConvE}上进行了实验。FB15k-237是开源知识图谱Freebase\upcite{freebase}的子集，存储了有关电影、演员、奖项等等现实世界的常识信息的。WN18RR则是开源知识图谱WordNet\upcite{wordnet}的子集，包含了英文单词中的语义信息，例如同义、反义、单词概念的上下层等多种单词语义关系。为了避免测试集出现逆关系泄露的问题，两个数据集中所有的逆关系都已经被去除。两个数据集的统计数据如表\ref{dataset_statistics}所示，其中训练集用于模型参数训练，验证集用于模型超参数调优，测试集用于模型性能评估。值得注意的是，这两个数据集中的关系数量存在差异，FB15k-237包含了237种Freebase中的不同关系，而WN18RR的关系种类数量为11，总的来说，相比于FB15k-237，WN18RR数据集更加的稀疏。

\begin{table}[htbp]
  \renewcommand\arraystretch{1.5}
  \caption{数据集统计信息}
  \centering
  \begin{tabular}{*{3}{c}}
    \toprule
    数据集 & FB15k-237 & WN18RR\\
    \midrule
    \#实体数量  & 10541 & 40943 \\
    \#关系数量 & 237 & 11\\
    \#训练集数量 & 272115 &86835\\
    \#验证集数量 &17535 &3034\\
    \#测试集数量 &20466 &3134\\
    \#实体平均度数 &42.7 &4.5\\
    \bottomrule
  \end{tabular}
  \label{dataset_statistics}
\end{table}

\subsection{实验评估策略}

知识图谱的链路预测任务被定义为实体排序预测任务。测试集中的每个三元组将在两种不同的场景中进行链路预测评估：给定头实体和关系下的尾实体预测$(s,r,?)$，以及给定尾实体和关系下的头实体预测$(?,r,o)$。在实践中，头实体预测以$(o,r^-1,?)$的形式执行。预测时，待预测的头实体或者尾实体将被每个候选实体替换，并计算每个候选三元组的得分，随后所有的候选三元组将按照分数降序进行排序，以获得基本事实三元组的准确排名，并根据排名来对评估指标进行计算。

在知识图谱补全任务中，平均排名(Mean Rank，MR)、倒数平均排名(Mean Reciprocal Rank，MRR)和前N名百分比(Hits@n)三种评估指标将用来评估模型的性能。假设测试集中待预测三元组的数量为$K$，$rank_i$为第$i$个三元组的正确实体在所有候选实体中的排序位置，则平均排序MR的计算方式为：
\begin{equation}
    MR = \frac{\sum_i rank_i}{K}
\end{equation}
MR代表了所有正确实体的平均排序位置，MR越小，说明正确实体的得分越高，排名越靠前，模型的性能更好。但是MR存在的最大问题则是它对于不同排序位置的预测效果投入的关注是一样的，例如，假设有两个三元组，其中一个三元组的正确实体的排名从105上升到了100，另一个三元组的正确实体的排名从5上升到了1，他们对于MR指标的贡献是一致的，但是一般来说，在实验中我们认为从5到1的提升是更有意义的，平均排名指标MR则忽略了这一点。

平均倒数排名MRR对于这个问题进行了改进，MRR计算的时候正确实体排名的倒数的平均值，而不是排名的平均值，具体计算公式为：
\begin{equation}
    MRR = \frac{1}{K} \sum_i \frac{1}{rank_i}
\end{equation}
通过这样的计算方式，排名越靠前的项会获得更大的权重占比，对于整体性能指标的贡献越大。和MR不同，MRR越高，代表模型的性能越好。

前N名百分比Hits@n指的则是所有测试三元组中正确实体的排序处于前n名的比例，计算方式为：
\begin{equation}
    Hits@n = \frac{\sum_i \left[1 \ if \ rank_i \leq n \ or \ 0\right] }{K}
\end{equation}
指标越高，代表模型的性能越好。在知识图谱补全任务中，常用的前N名百分比指标包括Hits@1，Hits@3和Hits@10。

此外，注意到对于一个待预测的三元组$(s,r,?)$，正确实体$o$的选项可能不止一个，例如（姚明，出生于，上海）和（姚明，出生于，中国）都是正确的事实。在计算评价指标时，其余的正确实体可能会导致当前测试三元组中的正确实体排名下降，对模型评估造成影响，因此本文和大多数基线模型类似，计算排序时除了基本事实三元组之外的所有正确三元组都被排除在排名之外。

\subsection{实验环境}

本文采用的实验环境中的服务器硬件和软件配置如表\ref{environment}所示。硬件配置方面，实验所采用的服务器的处理器规格为Intel(R) Core(TM) i9-10920X CPU @ 3.50GHz，内存大小为128G，使用的显卡型号为GeForce RTX 4090，对应的显存大小为24G；软件配置方面，使用的操作系统为Ubuntu 5.4.0-74，采用的编程语言为Python，版本为3.10.9，使用的深度学习框架及其对应的版本为Pytorch 1.13.1。

\begin{table}[htbp]
    \renewcommand\arraystretch{1.5}
    \caption{采用的实验环境}
    \centering
    \begin{tabular}{*{2}{c}}
      \toprule
      配置项目 & 版本/内容\\
      \midrule
      处理器  & Intel(R) Core(TM) i9-10920X CPU @ 3.50GHz \\
      内存 & 128G\\
      显卡 & GeForce RTX 4090\\
      显存 & 24G\\
      操作系统 & Ubuntu 5.4.0-74\\
      编程语言 & Python 3.10.9\\
      深度学习框架 & Pytorch 1.13.1\\
      \bottomrule
    \end{tabular}
    \label{environment}
\end{table}


\subsection{对比算法}

为了验证本文提出的NATLP方法在知识图谱补全任务上的有效性，实验部分本文选取了一些最具代表性的以及最先进的知识图谱补全方法作为基线模型与NATLP模型进行了对比实验，主要包含以下几类方法：

(1)基于翻译的知识图谱嵌入模型，包括TransE\upcite{TransE}，RotatE\upcite{RotatE}。

(2)基于张量分解的知识图谱嵌入模型，包括DistMult\upcite{DistMult}，ComplEx\upcite{ComplEx}。
 
(3)基于卷积神经网络的模型，包括ConvE\upcite{ConvE}，ConvR\upcite{ConvR}。

(4)基于图神经网络的知识图谱嵌入模型，包括R-GCN\upcite{R-GCN}，CompGCN\upcite{CompGCN}，KBGAT\upcite{KBGAT}，HKGN\upcite{HKGN}，SE-GNN\upcite{SE-GNN}以及MRGAT\upcite{MRGAT}。

\subsection{超参数设置}

NATLP模型在实验中采用的超参数是通过网格搜索在验证集上进行评估后得出的，主要涉及到的超参数有实体和关系嵌入的维度、关系特定的邻居实体信息构造中使用的卷积核的大小、卷积核的数量、不同神经网络层的Dropout概率、训练批次的大小、训练中的总迭代次数、训练中的最大学习率以及标签的平滑比例等。

实验中采用了Adamax\upcite{Adamax}优化器结合动态学习率调整策略进行模型的训练。在总迭代次数的前10\%内，模型的学习率将从0线性提升到最高，并在剩余迭代次数内线性下降到0。为了防止模型出现过度自信的现象，训练过程中以0.1的比率进行了标签平滑。NATLP模型在两个数据集上的具体的超参数设置见表\ref{NALTP_hyperparameter}所示。

\begin{table}[htbp]
  \renewcommand\arraystretch{1.5}
  \caption{NATLP模型超参数设置}
  \centering
  \begin{tabular}{*{3}{c}}
    \toprule
    超参数 & FB15k-237 & WN18RR\\
    \midrule
    实体和关系嵌入大小  & 320 & 320 \\
    卷积核大小 & 3$\times$3 & 3$\times$3\\
    卷积核数量 & 32 & 32\\
    Transformer网络层数& 4 & 4\\
    嵌入层Dropout概率 & 0.2 & 0.2\\
    Transformer中的Dropout概率 & 0.6 & 0.6\\
    训练批次大小 & 512 & 512\\
    总迭代次数& 300 & 500 \\
    最大学习率 & 0.001 & 0.02\\
    标签平滑比例 & 0.1 & 0.1\\
    \bottomrule
  \end{tabular}
  \label{NALTP_hyperparameter}
\end{table}

\section{实验结果与分析}

\subsection{整体实验结果分析}

不同模型在WN18RR数据集和FB15k-237数据集上的链路预测实验结果如表\ref{NATLP_result_tab}所示。文献\cite{49}在充分大的超参数搜索空间下采用统一的训练框架进行了大量的实验，探究了不同训练策略、模型架构和超参数搜索方法对于知识图谱嵌入模型性能的影响，发现如果选择合适的训练方法，许多浅层的知识图谱嵌入模型能够获得比原始文献中优秀得多的性能。因此TransE，RotatE，DistMult，ComplEx和ConvE模型在两个数据集上的实验结果直接选取文献\cite{49}中经过大量调参后的最优结果。另外，文献\cite{50}指出KBGAT中存在评估策略不当以及测试集数据泄露的问题，因此KBGAT的实验结果选取自文献\cite{50}中经过修正后的结果。

\begin{table}[htbp]
  \begin{center}
      \caption{NATLP实验结果}
      \renewcommand\arraystretch{1.5}
      \setlength{\tabcolsep}{5pt}
      \begin{tabular}{*{11}{c}}
          \toprule
          \multirow[vpos]{2}{*}[-0.8ex]{模型} & \multicolumn{5}{c}{WN18RR} & \multicolumn{5}{c}{FB15k-237}\\
          \cmidrule(lr){2-6}\cmidrule(lr){7-11}
          &MRR & MR & Hits@1 &Hits@3 & Hits@10&MRR & MR & Hits@1 &Hits@3 & Hits@10\\
          \midrule
          TransE&0.228&-&0.053&0.368&0.520&0.313&-&0.221&0.347&0.497\\
          RotatE&0.478&-&0.439&0.494&0.553&0.333&	-&0.240&0.368&0.522\\
          \cmidrule{1-11}
          DistMult&0.452&-&0.413&0.466	&0.530	&0.343	&-	&0.250	&0.378	&0.531\\
          ComplEx&0.475&-&0.438	&0.490	&0.547	&0.348	&-	&0.253	&0.384	&0.536\\
          \cmidrule{1-11}
          ConvE&0.442&-&0.411&0.451	&0.504&	0.339	&-&	0.248&	0.369	&0.521\\
          ConvR&0.475&-&0.443&	0.489&	0.537&	0.350&	-&	0.261&	0.385&	0.528\\
          \cmidrule{1-11}
          R-GCN & -&-&-&-&-&0.248&-&0.153&0.258&0.414\\
          CompGCN&0.479&3533&0.443	&0.494	&   0.546&	0.355	&197	&0.264	&0.390&	0.535\\
          KBGAT&0.412&\textbf{1921}&-&	-&	0.554	&0.157	&270	&-&	-&	0.331\\
          SE-GNN&0.484&3211&0.446&	\underline{0.509}&	\underline{0.572}	&\underline{0.365}& \textbf{157}	&\underline{0.271}	&\underline{0.399}	&\underline{0.549}\\
          MRGAT&0.481&-&0.443&0.501&0.568&0.358	&-&0.266&0.386&0.542\\
          HKGN&\underline{0.487}&\underline{2468}&\underline{0.448}&0.505&0.561&\underline{0.365}&194&\underline{0.271}&0.397&0.544\\
          \cmidrule{1-11}
          \textbf{NATLP}&\textbf{0.505}&2687&\textbf{0.465}&\textbf{0.519}&\textbf{0.576}&\textbf{0.374}&\underline{181}&\textbf{0.281}&\textbf{0.411}&\textbf{0.560}\\
          % TKGE-PN&\textbf{0.510}&2540&\textbf{0.467}	&\textbf{0.522}	&\underline{0.590}	&\textbf{0.379}	&160	&\underline{0.288}	&\textbf{0.414}	&\textbf{0.562}\\
          \bottomrule
      \end{tabular}
      \label{NATLP_result_tab}
  \end{center}
\end{table}

表中加粗项为每项指标的最高值，下划线项为每项指标的次高值。从表\ref{NATLP_result_tab}中可以观察到，在两个基准数据集的绝大多数指标上，NATLP都取得了最优的效果，相对于次优结果，在FB15k-237数据集上，NATLP在MRR、Hits@1、Hits@3和Hits@10四个指标上分别取得了3.6\%，3.7\%， 1.9\%， 0.6\%的性能提升；在WN18RR数据集上，NATLP在MRR、Hits@1、Hits@3和Hits@10四个指标上分别取得了2.4\%，3.6\%， 3.0\%和2.0\%的性能提升，这表明本文提出的NALTP方法在链路预测任务上有着很好的表现，证明了NATLP模型的有效性。同样使用了注意力机制，相比于HKGN以及MRGAT等基于图神经网络的方法，NATLP有着可观的性能提升，证明了Transformer网络强大的表达能力以及在知识图谱嵌入领域的应用潜力。

\subsection{模型关键设计分析}

为了验证NATLP模型中关键设计：关系特定的邻居实体信息构造以及邻域感知Transformer模块的有效性，本文进行了多方面的对比实验来验证关键设计的效果。

首先，为了验证关系特定的邻居实体信息构造中参数生成网络以及全局关系嵌入对于链路预测任务的作用，本文在两个数据集上分别以三种设置进行了消融实验，分别是（1）原始NATLP模型，未对模型进行任何改动；（2）消融了参数生成网络的NATLP模型，同一实体在不同关系下进行信息构造中共享完全相同的网络参数；（3）消融了全局关系嵌入的NATLP模型，参数生成网络仅依赖于关系嵌入进行参数生成。实验结果如表\ref{NATLP_ablation1}所示。

\begin{table}[htbp]
  \begin{center}
      \caption{关系特定的邻居实体信息构造消融实验}
      \setlength{\tabcolsep}{8pt}
      \renewcommand\arraystretch{1.5}
      % \renewcommand{\arraystretch}{1}
      \begin{tabular}{*{7}{c}}
          \toprule
          数据集 & 模型设置 & MRR&MR&Hits@1&Hits@3&	Hits@10\\
          \midrule
          \multirow{3}{*}{WN18RR}&NATLP&0.505&2504&0.466&0.519&0.578\\
          &消融参数生成网络&0.496&2399&0.456&0.512&0.575\\
          &消融全局关系嵌入&0.503&2519&0.461&0.518&0.578\\
          \cmidrule{1-7}
          \multirow{3}{*}{FB15k-237}&NATLP&0.376&161&0.284&0.411&0.561\\
          &消融参数生成网络&0.367&145&0.274&0.404&0.555\\
          &消融全局关系嵌入&0.373&175&0.279&0.411&0.558\\
          \bottomrule
      \end{tabular}
      \label{NATLP_ablation1}
  \end{center}
\end{table}

从表\ref{NATLP_ablation1}中实验结果可以观察到，在对参数生成网络进行消融后，模型的在两个数据集上的链路预测性能都有了明显的下降，这证明了相比于采用统一的网络参数进行消息构造，关系特定的网络参数能够更好地捕捉实体中关系相关的特定特征，挖掘相关的语义信息，提高任务性能；注意到消融了参数生成网络之后，相比于WN18RR数据集上的表现，NATLP模型在FB15k-237数据集上的性能下降更为严重，本文认为这样的差异主要是由于两个数据集上的关系种类差异所导致的，FB15k-237数据集中的关系种类为237种，远远超过WN18RR数据集上的11种，因此采用统一的网络参数时模型在FB15k-237数据集上损失的信息更多。此外，去除全局关系嵌入后模型在两个数据集上的性能也有所下降，证明了捕捉关系之间共同特征的有效性。

此外，为了验证邻域感知Transformer模块中基于实体节点间最短距离的偏置项以及基于节点度数的偏置项的有效性，本文在两个数据集上以四种设置进行了NATLP模型的消融实验，分别是（1）原始NATLP模型，未对模型进行任何改动；（2）消融了基于实体节点间最短距离的偏置项的NATLP模型；（3）消融了基于节点度数的偏置项的NATLP模型；（4）同时对两个偏置项进行了消融的NATLP模型。具体实验结果如表\ref{NATLP_ablation2}所示。

\begin{table}[htbp]
  \begin{center}
      \caption{邻域感知Transformer模块消融实验}
      \setlength{\tabcolsep}{8pt}
      \renewcommand\arraystretch{1.5}
      % \renewcommand{\arraystretch}{1}
      \begin{tabular}{*{7}{c}}
          \toprule
          数据集 & 模型设置 & MRR&MR&Hits@1&Hits@3&	Hits@10\\
          \midrule
          \multirow{4}{*}{WN18RR}&NATLP&0.505&2504&0.466&0.519&0.578\\
          &消融节点最短距离的偏置项&0.500&2603&0.457&0.515&0.573\\
          &消融节点度数偏置项&0.501&2570&0.459&0.517&0.578\\
          &消融两个偏置项&0.497&2856&0.454&0.515&0.570\\
          \cmidrule{1-7}
          \multirow{4}{*}{FB15k-237}&NATLP&0.376&161&0.284&0.411&0.561\\
          &消融节点最短距离的偏置项&0.373&180&0.280&0.409&0.557\\
          &消融节点度数偏置项&0.372&184&0.281&0.409&0.554\\
          &消融两个偏置项&0.369&179&0.277&0.409&0.550\\
          \bottomrule
      \end{tabular}
      \label{NATLP_ablation2}
  \end{center}
\end{table}

通过表中结果可以发现，无论是消融了节点间最短距离的偏置项还是节点度数的偏置项，模型在两个数据集上的性能都会出现下降，证明了两种结构信息对于链路预测任务的重要性。


\section{本章小结}

本章对于基于领域感知的Transformer模型NALTP的实验部分进行了介绍，首先对本文中实验的基本方案设计进行了说明，包括实验采用的数据集，模型的评估策略以及实验的硬件和软件环境，并介绍了用来对比NATLP的基线模型。随后论文对NALTP模型的整体实验结果进行了介绍，证明了模型的有效性；最后通过消融实验对NATLP模型的中的关键设计：关系特定的邻居实体信息构造以及邻域感知Transformer模块进行了具体的探究和分析。