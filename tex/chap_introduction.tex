% !TeX root = ../Template.tex
% [绪论]
% 此处为本LaTeX模板的简介
\chapter{绪论}

%%============================
\section{研究背景与意义}
论文选题来源于国家重点研发计划课题“稀土催化材料专用数据库及全流程数字化研发平台”，本文研究高效的知识图谱补全方法，为稀土催化材料知识图谱构建和应用提供技术支撑。

稀土是由镧系元素和与其密切相关的钪和钇等化学元素组成，稀土的存在能有效提高催化剂的储氧能力、提高活性金属的分散度、降低贵金属用量、促进水气转化和蒸汽重整反应等性质，在催化材料领域中有着重要的应用。
% 知识图谱(Knowledge Graph, KG)是知识库的一种主要表现形式，是由事实三元组（头实体、关系、尾实体）表示的结构化知识的集合，在多个领域中已经得到了广泛的应用。
稀土催化材料知识图谱存储着稀土催化材料的合成方式、理化性质、组成结构等重要信息，被应用于稀土催化材料合成等任务中，能够帮助稀土催化材料降低开发成本、减少开发周期。然而，由于稀土材料领域的不断研究发展带来的知识的动态变化，和大多数知识图谱一样，稀土催化材料知识图谱往往是不完全的，难以囊括领域内的所有知识，对其在上层任务中的应用造成了阻碍。因此，为了挖掘图谱内蕴含的丰富信息，完善稀土催化材料知识图谱，知识图谱补全(Knowledge Graph Completion, KGC)，又称链路预测任务，成为了知识图谱领域的热门研究方向。

知识图谱补全需要挖掘图谱中隐藏的语义信息，但是知识图谱中的事实三元组一般是以文本形式进行储存的，无法直接利用，需要首先寻找一种合适的方式来对语义信息进行表达。传统方法一般通过特征工程进行，效率低且可移植性较差，因此不少研究者投入了自动化知识补全的研究。

目前，知识图谱补全的主流解决方案是知识图谱嵌入(Knowledge Graph Embedding, KGE)，又称知识图谱表示学习(Knowledge Graph Representation Learning)。它的核心思想是将图谱中的实体和关系投影到低维向量空间中，通过预先设计好的得分函数(Scoring Function)评估事实三元组的合理性，并基于知识图谱中的已有事实，最大化对正确事实三元组的预测概率。通过这种方式获得的嵌入表示不仅可以用于知识图谱补全，还能够用于语义搜索、问答和推荐系统等下游任务中。

传统的知识图谱表示学习方法主要考虑如何在单纯的三元组上进行学习，但这种方式存在较大的缺陷：
% 知识图谱本身是一个带标签的有向图，单纯考虑三元组的方法忽略了三元组之间的联系，
忽略了知识图谱本身的图结构信息。基于图神经网络的模型通过学习中心实体的局部邻域结构一定程度上解决了以上的问题，获得了更加优秀的性能，但依然存在不足：首先图神经网络的网络结构较浅，限制了模型的表达能力；另外，
% 基于图神经网络的方法的感受域与其网络层数相关，随着图神经网络层数的增加，相邻节点的感受域重叠程度升高，现有的方法会遭遇过度平滑的问题而导致性能下降，
基于图神经网络的方法随着网络层数的提升会遭遇过度平滑的问题，导致其只能捕捉单个实体附近1-2跳内的局部邻域信息，缺乏利用长距离依赖的能力。针对以上问题，本文研究基于Transformer的知识图谱补全方法。Transformer被公认为是建模序列数据的最强大的神经网络，不少工作致力于研究将Transformer网络应用到知识图谱嵌入工作中。本文研究利用Transformer强大的表达能力，结合知识图谱中的局部邻域和图路径两种图结构来学习图谱中的短距离依赖、长距离依赖乃至全局信息，实现更加准确的知识图谱补全，支持稀土催化材料知识图谱构建和应用。


\section{国内外研究现状}

\subsection{相关研究发展现状}
知识图谱(Knowledge Graph, KG)的现代含义由2012年谷歌知识图谱的发布而确立，它是知识库的一种主要表现形式，是由事实三元组（头实体、关系、尾实体）表示的结构化知识的集合。图谱中的节点为实体，表示现实世界中的具体事物；图谱中的节点为关系，表示实体之间的联系。目前知识图谱已经在多个人工智能领域中得到了广泛的应用，例如语义搜索、问答和推荐系统。主流的开放知识图谱包括FreeBase，Wikidata，DBpedia和YAGO等，它们通常包含使用数十亿个实体和关系构建的大量事实。然而，即使是大规模知识图谱也不可避免的是不完全的，缺乏部分事实，这限制了知识图谱在现实世界中的应用。因此，近年知识图谱补全又称链路预测任务，成为了知识图谱领域的热门研究方向，尝试在给定事实三元组中的头（尾）实体和关系的情况下，自动预测缺失的尾（头）实体。

目前，知识图谱嵌入是知识图谱补全任务的主流解决方案,它将图谱中的实体和关系转化为低维向量空间中的向量，并用得分函数估计事实三元组正确的概率。现阶段对于知识图谱嵌入算法的研究，根据方法的核心思想和实现方式的不同，可以划分为传统的知识图谱嵌入方法，基于图神经网络的知识图谱嵌入方法，基于Transformer的知识图谱嵌入方法和融合多源信息的知识图谱嵌入方法。

传统的知识图谱嵌入方法仅独立研究知识图谱中的事实三元组，主要包含基于翻译的方法、基于张量分解的方法和引入神经网络后的基于多层神经网络方法、基于卷积神经网络的方法。

基于翻译的方法是最早被提出的一类知识图谱嵌入方法，起源于2013年的TransE模型，核心思想是将知识图谱中的关系视为一个实体到另一个实体的翻译，又被称为平移距离模型。由于TranE无法有效建模知识图谱中的一对多、多对一、多对多关系，后续基于TransE进行改进并衍生出了如TransH、TransR、TransD等模型，不断丰富模型的表达能力。基于翻译的方法最大的优点在于其模型结构简单、计算速度快、易于理解且可解释性较强，但另一方面浅层的模型结构也限制了该类方法的表达能力。

以RESCAL为代表的基于张量分解的方法则将整个知识图谱表示为一个高维的稀疏张量，通过对其进行张量分解来获得实体和关系的嵌入。RESCAL用一个维度为$N\times N\times M$的张量来表示一个实体数量为$N$,关系数量为$M$的知识图谱，其中第$i$行$j$列深度为$k$的元素值为1时表示实体$i$和实体$j$之间存在关系$k$。通过张量分解，模型最终能够得到用一维向量表示的实体嵌入和用二维矩阵表示的关系嵌入。继RESCAL之后，基于张量分解的思想提出的DistMult、ComplEx、ANALOGY等一系列模型分别从强化模型表达能力以及压缩模型参数两方面对RESCAL模型进行了改进。DisMult将关系嵌入进行了简化，选用了对角矩阵替代了RESCAL的二维矩阵，降低了模型的复杂度并获得了更优的性能；ComplEx则将模型从实数域扩展到了复数域，提高了模型的表达能力。总的来说，基于张量分解的方法可解释性较强，并能够捕捉到实体和关系之间的双线性关系，但和基于翻译的方法类似，浅层的模型结构很难有效的学习图谱中蕴含的复杂信息，模型表达能力较弱。

而随着神经网络的发展，大量基于神经网络的知识图谱嵌入方法开始涌现。使用神经网络进行知识图谱嵌入能够建立更加复杂的模型，自动学习知识图谱当中蕴含的特征，模型的表达能力更强，更加充分地学习和表达知识图谱中的信息。这其中最早提出的是基于多层神经网络的方法，SME、NTN、MLP等模型直接使用多层的神经网络去拟合知识图谱，以事实三元组的嵌入作为模型的输入，输出三元组正确的概率。这类方法相较之前没有神经网络结构的方法在性能上有了提升，但网络结构相对简单，可解释性较差。

而受到计算机视觉领域的研究方法的启发，随后有不少工作尝试将卷积引入知识图谱嵌入领域，大量基于卷积神经网络的方法被提出，其中最具代表性的方法为ConvE。ConvE将事实三元组中的头实体和关系的一维向量嵌入，重组为二维张量并对其进行卷积操作，将结果向量化之后经过神经网络层，随后和候选实体的嵌入进行点乘，输出事实三元组的正确概率。基于ConvE的思想，有不少方法提出了进一步的改进。ConvR使用关系嵌入构造卷积核，减少了网络的参数；ConvKB通过在实体和关系的相同维度上进行卷积，能够捕获在实体和关系之间相同维度上的联系；InteractE则将重组后二维张量修改为棋盘式，大大提升了头实体和关系之间的交互。

以上提到的知识图谱嵌入方法研究的对象是知识图谱中独立的三元组，这导致这些模型忽略了知识图谱的结构信息，因此被统一归类为传统的知识图谱嵌入方法。例如，这些方法没有办法感知到头实体的邻居实体，无法充分利用每个实体丰富的邻域结构，不仅链路预测的性能受到限制，而且也缺乏嵌入空间的可解释性。而基于图神经网络(Graph Neural Network, GNN)的知识图谱嵌入方法则利用图卷积神经网络来捕获图谱中的图结构信息，中心实体接受来自邻居实体与邻居关系的消息，并依此对实体和关系的嵌入表示进行更新。

R-GCN是第一个利用图卷积神经网络学习知识图谱表示的方法，整体采用编码器-解码器架构。编码器部分通过图神经网络对图结构进行建模，在R-GCN的信息传播过程中，中心实体会接受来自出边、入边和自循环边三个方向的信息；通过多次信息传播模型能够获得多阶邻居的信息。解码器部分则基于编码的信息对三元组进行打分。后续提出的方法基本沿用了R-GCN的编码器-解码器架构，并在此基础上进行改进。SACN模型则基于关系类型将实体的邻域划分为带权值的子图进行聚合。TransGCN设计了实数域和复数域下两种基于翻译的思想的编码器。

而收到自然语言处理和计算机视觉领域中注意力机制的成功的启发，有不少工作尝试将注意力机制引入到了基于图神经网络的知识图谱嵌入方法中来并取得了不错的效果。KBGAT是首个在知识图谱嵌入领域应用图注意力网络的方法，模型能够自动分辨出哪些邻居实体的信息对于中心实体是更加重要的。RGHAT将注意力机制进行了进一步的细分，引入了关系注意力机制和实体注意力机制，实现了更细粒度的建模。EIGAT则通过随机游走算法引入了全局实体重要性，将局部注意力机制和知识图谱的全局信息进行了结合。

% 基于图神经网络的方法的成功证明了实体的局部邻域蕴含了丰富的信息，但知识图谱的结构信息除了常见的局部邻域之外还有多种表达形式，例如图路径和子图等。在知识图谱中，图路径被定义为图谱中的实体-关系链，例如(Yao Ming, Born In, Shanghai, City Of, China)。和基于图神经网络的方法利用中心实体的局部邻域进行链路预测不同，基于图路径的方法尝试利用知识图谱中的图路径信息来捕获实体与实体之间的长距离依赖。TransE-Comp和PTransE尝试建模两个实体之间的图路径上多跳关系构成的复合关系。Chain和RSN则对循环神经网络(Recurrent Neural Network, RNN)进行了改造，以学习图路径上的所有相邻实体和关系信息之间的依赖。Interstellar分析了挖掘图路径信息的重要性，并将知识图谱图路径学习问题定义为RNN神经网络架构搜索问题，并设计了一种特定于知识图谱嵌入领域的混合搜索算法以及搜索空间。
基于图神经网络的方法通过对实体的邻域结构进行学习从而获得了阶段性的成功，性能普遍优于传统的知识图谱嵌入模型。但是图神经网络的表达能力虽然相较于传统方法的多层神经网络和卷积神经网络有了较大的提升，但是依然不足以充分学习知识图谱中的语义信息。针对这个问题，许多研究者尝试引入表达能力更强的架构。Transformer是注意力机制方面里程碑式的工作，被认为是建模序列数据的最强大的神经网络，基于Transformer的模型变体在计算机视觉和编程语言领域中也表现出了出色的性能，因此目前有不少工作致力于研究将Transformer结构应用到知识图谱嵌入工作中，KG-BERT是其中较早的方法，KG-BERT利用Transformer对知识图谱中的独立三元组进行学习，同时结合了实体和关系的文本信息。而后续出现的不少基于Transformer的知识图谱嵌入方法将知识图谱的图结构也纳入了考虑，这些方法的特点是对Transformer的编码方式和注意力机制进行改造，使得模型能够学习到知识图谱中的事实三元组和结构信息并进行预测，典型方法有HittER和Relphormer。HittER采用分层Transformer架构对实体的局部邻域进行了建模。Relphormer提出了一种用于知识图谱嵌入的Transformer架构变体，并提出了一种Triple2Seq序列化算法来解决知识图谱中边和节点的异构性问题。

融合多源信息的知识图谱嵌入方法则是在以上几类算法的基础上利用更多的额外信息来进行知识图谱嵌入，例如图路径、文本描述、实体类别、人工预定义规则或者时间顺序等。这些信息能够帮助模型从不同的维度对知识图谱进行建模，提高知识图谱补全的效果。

基于图路径的方法尝试利用知识图谱中的图路径信息来捕获实体与实体之间的长距离依赖。在知识图谱中，图路径被定义为图谱中的实体-关系链，例如(Yao Ming, Born In, Shanghai, City Of, China)。对于每个待预测的事实三元组，这类方法一般通过随机游走等方式获得若干条图路径，并基于图路径学习实体和关系的嵌入。TransE-Comp和PTransE尝试建模两个实体之间的图路径上多跳关系构成的复合关系。Chain和RSN则对循环神经网络(Recurrent Neural Network, RNN)进行了改造，以学习图路径上的所有相邻实体和关系之间的依赖。Interstellar分析了图路径信息对知识图谱嵌入的重要性，并将图路径学习问题定义为循环神经网络架构搜索问题，并设计了一种特定于知识图谱嵌入领域的混合搜索算法以及搜索空间。

除了结构信息之外，知识图谱中还包含了丰富的文本信息，每个实体和关系一般都有名称和对应的文本描述，蕴含对应的自然语言语义。NTN对文本描述的词向量进行平均来初始化实体的向量表示。LMKE采用预训练语言模型进行知识图谱嵌入，将文本描述转化为对应的词向量并将实体和关系投影到相同的向量空间中进行学习，对于知识图谱中的长尾实体获得了很好的嵌入效果。

此外，考虑到现实世界是在不断发展的，知识图谱中现有的知识可能会失效，也有新的知识会被添加的知识图谱中来，针对这个特点，tTransE、tTransH和tTransR等方法在知识图谱中引入了时序信息，对TransE、TransH和TransR进行了改进。

总的来说，融合多源信息的知识图谱嵌入方法通过引入额外的信息获得了更好的知识图谱嵌入效果。但是引入其他形式的信息往往需要额外的数据准备工作，有些知识图谱甚至无法获取对应的信息，可移植性较差；另外数据的质量也会对模型的性能造成影响。

\subsection{对比分析}
通过调研国内外知识图谱嵌入方法，本文对于各类知识图谱嵌入方法进行了总结与对比，各种方法的优缺点如表\ref{ComparativeAnalysis}所示。



\begin{table}
  \caption{各类知识图谱嵌入方法对比分析}
  \label{ComparativeAnalysis}
  \centering
  \renewcommand\arraystretch{1.5}
  \begin{tabular}{lp{6cm}p{5cm}}
    \toprule
    \multicolumn{1}{c}{\textbf{方法类型}} & \multicolumn{1}{c}{\textbf{优点}} & \multicolumn{1}{c}{\textbf{缺点}}\\
    \midrule
    基于翻译 & 结构简单，计算速度快，可解释性较强& 模型表达能力弱\\
    基于张量分解 & 可解释性较强，能够捕捉实体与关系之间的双线性关系 & 模型表达能力较弱\\
    基于多层神经网络 & 表达能力相比于之前的方法更强 & 容易出现过拟合的问题，嵌入的维度对性能的影响较大\\
    基于卷积神经网络 & 实体和关系之间的交互得到了增强，参数数量较少&没有利用到知识图谱的图结构信息\\
    基于图神经网络 & 能够学习到实体的局部邻域信息，模型性能相较于传统方法得到了提高 & 模型的表达能力不足以充分学习知识图谱的语义信息，另外捕获长距离信息的能力不足\\
    基于Transformer &通过自注意力机制和更复杂的网络结构获得了更强大的模型表达能力 & 模型复杂度高，不适用于大规模知识图谱，无法直接利用图结构信息\\
    融合多源信息 & 将现有方法与额外的信息进行结合，获得了更好的知识图谱嵌入效果 & 需要额外的数据准备工作，信息的质量对模型的性能影响较大，可移植性相对较差\\
    \bottomrule
  \end{tabular}
\end{table}

\section{研究目标及内容}
\subsection{研究目标}
本课题的研究目标是设计基于Transformer的知识图谱嵌入模型，利用Transformer模型的强大表达能力来学习实体和关系的合适嵌入表示，对知识图谱进行自动化补全。本课题针对传统知识图谱嵌入和基于图神经网络的方法表达能力弱、图信息利用不足、无法捕获长距离信息乃至全局信息的问题，研究如何基于Transformer网络和知识图谱的特点，采用合适的方式采样和编码知识图谱中局部邻域和图路径两类图结构，并进行综合利用以充分发挥Transformer网络强大的表达能力，最终得到能够尽可能拟合现有图谱的合适表示。

\subsection{研究内容}


针对本课题的研究目标，本课题的主要研究路线如图所示。基于Transformer网络以及知识图谱本身的特点，本课题开展的研究内容主要包括以下几个方面：

（1）基于Transformer的模型对于图结构的捕获研究

在Transformer中，任意一个位置都能直接感知到其他位置的输入信息，这导致模型无法直接捕捉到输入之间的相对位置关系，因此在处理序列数据时，采用的方式一般是为每个位置的输入添加对应的位置编码，标识输入与输入之间的前后位置关系。但在知识图谱中节点并不是顺序排列的，因此本文的主要研究内容之一就是设计一种合适方案让Transformer模型能够学习到知识图谱的拓扑结构，实现对知识图谱结构的感知。

（2）图路径采样算法研究

本课题计划通过对知识图谱中的图路径信息学习来挖掘实体与实体之间的长距离依赖，因此为了提升模型性能，对于当前的待遇测事实三元组，如何采样到高质量的图路径是首先需要解决的问题。因此本文计划研究设计合适的采样策略，实现高效的图路径采样，提高模型捕获长距离依赖的能力。

（3）不同图结构信息的结合方案研究

基于图神经网络的模型通过聚合消息的方式实现了对于中心实体局部邻域结构的感知，但无法捕捉实体之间长距离的依赖；基于图路径的方法能够挖掘到更远距离的依赖，但忽略了实体丰富的局部邻域。因此，本文的主要研究内容之一是设计合适的模型结构实现对于以上两类图结构信息的综合利用，实现对于图谱中长短距离信息的捕捉。

（4）实验与验证

在完成以上研究内容，实现完整的知识图谱补全模型之后，设计相应实验方案，通过平均排名、平均倒数排名等指标在主流公开数据集上与基线模型进行性能对比，验证本文提出的模型的有效性；并且通过设计合适的消融实验，验证模型关键设计的有效性。



%%============================
\section{内容要求}
论文应立论正确、推理严谨、说明透彻、数据可靠。

论文应结构合理、层次分明、叙述准确、文字简练、文图规范。对于涉及作者创新性工作和研究特点的内容应重点论述，做到数据或实例丰富、分析全面深入。文中引用的文献资料必须表明来源，使用的计量单位、绘图规范应符合国家标准。

论文内容包括：选题的背景、依据及意义；文献及相关研究综述、研究及设计方案、实验方法、装置和实验结果；理论的证明、分析和结论；重要的计算、数据、图表、曲线及相关分析；必要的附录、相关的参考文献目录等，如表\ref{tab:papercomponents}。

\centerline{-----------$\downarrow$-----------Space Check-----------$\downarrow$-----------}
\begin{table}[h]
  \caption{学位论文组成}
  \label{tab:papercomponents}
  \centering
  \begin{tabular}{cp{16\ccwd}p{4cm}}
    \toprule
    {\bfseries 装订顺序} & \multicolumn{1}{c} {\bfseries 内容} & \multicolumn{1}{c} {\bfseries 说明}  \\
    \midrule
    1 & 封面（中、英文）& \\
    2 & 题名页          & \\
    3 & 独创性声明和使用授权书 & \\
    4 & 中文摘要        & \\
    5 & 英文摘要        & \\
    6 & 目录            & \\
    7 & 图表清单及主要符号表  & 根据具体情况可省略 \\
    8 & 主体部分        & \\
    9 & 参考文献        & \\
    10& 附录            & \\
    11&攻读博士学位期间取得的研究成果/ 攻读硕士学位期间取得的学术成果 & 注意博士的是研究成果，硕士的是学术成果 \\
    12& 致谢            & \\
    13& 作者简介        & 硕士学位论文无此项 \\
    \bottomrule
  \end{tabular}
\end{table}
\centerline{-----------$\uparrow$-----------Space Check-----------$\uparrow$-----------}

%%----------------------
\subsection{封面}
\label{sec:error1}

{\bfseries 中图分类号}：根据论文主题内容对照《中国图书分类法》选取；

{\bfseries 论文编号}：北航单位代码（10006）＋学号；

{\bfseries 密级}：保密审批通过论文需在封面、题名页直接把相应的“密级☆”及“保密期限”表注在{\bfseries 左上角}（非密论文务必将相应内容清除），并将《涉密论文审批通知》复印件附在论文最后。密级按由低到高可分为“秘密”、“机密”、“绝密”三级，保密期限可分为“3年”、“5年”、“10年”、“永久”，例如“密级☆ 5年”。鼓励尽量对学位论文进行去密处理；

{\bfseries 学科专业}：以国务院学位委员会批准的授予博士、硕士学位和培养研究生的学科、专业目录中的学科专业为准，一般为二级学科。对专业学位应填相应的工程领域（如航空工程）或专业学位（工商管理硕士）名称；

{\bfseries 指导教师}：以研究生院批准招生的为准，一般只能写一名指导教师，如有经主管部门批准的副指导教师或联合指导教师，可增1名指导教师；

{\bfseries 培养院系}：应准确填写培养的学院或独立系的全称。

%%----------------------
\subsection{题名页}

{\bfseries 研究方向}：只填写一个，应比学科专业的二级学科更具体，但比论文关键词的覆盖面更广，一般为学科分类号对应的研究方向；

{\bfseries 申请学位级别}：学科门类+学位，学科门类有哲学、经济学、法学、教育学、文学、历史学、理学、工学、农学、医学、军事学和管理学等12个学科门类以及专业学位类别（工程、工程管理、公共行政管理、软件工程）；

{\bfseries 工作完成日期}：包括学习日期（从研究生入学至毕业时间）、论文提交日期（论文送审评阅时间）、论文答辩日期、学位授予日期；除学位授予日期可以不填外，其他均需准确填写，一律用阿拉伯数字填写日期；

{\bfseries 学位授予单位}：北京航空航天大学。

%%----------------------
\subsection{独创性声明和使用授权书}

必须由作者、指导教师亲笔签名并填写日期。

%%----------------------
\subsection{摘要}

中文摘要包括“摘要”字样，摘要正文及关键词。对于中英文摘要，都必须在摘要的最下方另起一行。

摘要是学位论文内容的简短陈述，应体现论文工作的核心思想。论文摘要应力求语言精炼准确。博士学位论文的中文摘要一般约800$\sim$1200字；硕士学位论文的中文摘要一般约500字。摘要内容应涉及本项科研工作的目的和意义、研究思想和方法、研究成果和结论。博士学位论文必须突出论文的创造性成果，硕士学位论文必须突出论文的新见解。

关键字是为用户查找文献，从文中选取出来揭示全文主体内容的一组词语或术语，应尽量采用词表中的规范词（参考相应的技术术语标准）。关键词一般3$\sim$5个，按词条的外延层次排列（外延大的排在前面）。关键词之间用逗号分开，最后一个关键词后不打标点符号。

为了国际交流的需要，论文必须有英文摘要。英文摘要的内容及关键词应与中文摘要及关键词一致，要符合英语语法，语句通顺，文字流畅。英文和汉语拼音一律为Times New Roman体，字号与中文摘要相同。

%%----------------------
\subsection{目录}

目录按章、节、条和标题编写，一般为二级或三级，目录中应包括绪论（或引言）、论文主体章节、结论、附录、参考文献、附录、攻读学位期间取得的成果等。

%%----------------------
\subsection{图表清单及主要符号表}

如果论文中图表较多，可以分别列出清单置于目录之后。图的清单应有序号、图题和页码，表的清单应有序号、标题和页码。
全文中常用的符号、标志、缩略词、首字母缩写、计量单位、名词、术语等的注释说明，如需汇集，可集中在图和表清单后的主要符号表中列出，符号表排列顺序按英文及其相关文字顺序排出。

%%----------------------
\subsection{主体部分}

一般应包括：绪论（或引言）、正文、结论等部分。

每章应另起一页。章节标题不得使用标点符号，尽量不采用英文缩写词，对必须采用者，应使用本行业的通用缩写词。
三级标题的层次对理工类建议按章（如“第一章”）、节（如“1.1”）、条（如“1.1.1”）的格式编写；对社科、文学类建议按章（如“一、”）、节（如“（一）”）、条（如“1、”）的格式编写，各章题序的阿拉伯数字用Times New Roman字体。

博士学位论文一般为6$\sim$10万字，硕士学位论文一般为3$\sim$5万字。

%%----------------------
\subsection{参考文献}

学术研究应精确、有据、坦诚、创新、积累。而其中精确、有据和积累需要建立在正确对待前人学术成果的基础上。凡有直接引用他人成果之处，均应加标注说明列于参考文献中，以避免论文抄袭现象的发生。

研究生论文参考文献著录及标引按照国家标准《文后参考文献著录规则》（GB774）和中国博硕士学位论文编写与交换格式。

%%----------------------
\subsection{附录}

附录作为论文主体的补充项目，并不是必需的。

%%----------------------
\subsection{成果}

对于博士学位论文，名称用“攻读博士学位期间取得的研究成果”，一般包括：

攻读博士学位期间取得的学术成果：攻读博士学位期间取得的学术成果：列出攻读博士期间发表（含录用）的与学位论文相关的学位论文、发表专利、著作、获奖项目等，书写格式与参考文献格式相同；

攻读博士期间参与的主要科研项目：列出攻读博士学位期间参与的与学位论文相关的主要科研项目，包括项目名称，项目来源，研制时间，本人承担的主要工作。

对于硕士学位论文，名称用“攻读硕士学位期间取得的学术成果”，只列出攻读硕士学位期间发表（含录用）的与学位论文相关的学位论文、发表专利、著作、获奖项目等，书写格式与参考文献格式相同。

%%----------------------
\subsection{致谢}
致谢中主要感谢指导教师在和学术方面对论文的完成有直接贡献及重要帮助的团体和人士，以及感谢给予转载和引用权的资料、图片、文献、研究思想和设想的所有者。致谢中还可以感谢提供研究经费及实验装置的基金会或企业等单位和人士。致谢辞应谦虚诚恳，实事求是，切记浮夸与庸俗之词。

%%----------------------
\subsection{作者简介}

博士学位论文应该提供作者简介，主要包括：姓名、性别、出生年月日、民族、出生的；简要学历、工作经历（职务）；以及攻读博士学位期间获得的其他奖项（除攻读学位期间取得的研究成果之外）。
